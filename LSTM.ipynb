{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKJI33k1628H7jWnlkQ6Vl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abishekraja018/SDC-GENAI/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkEOpKlNKXRZ",
        "outputId": "0cee5482-4257-4f15-c803-fe5c9922fb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Training...\n",
            "\n",
            "Epoch 010, Loss: 1.1302, Prediction: llll\n",
            "Epoch 020, Loss: 0.7786, Prediction: lllo\n",
            "Epoch 030, Loss: 0.4062, Prediction: lllo\n",
            "Epoch 040, Loss: 0.1789, Prediction: ello\n",
            "Epoch 050, Loss: 0.0777, Prediction: ello\n",
            "Epoch 060, Loss: 0.0363, Prediction: ello\n",
            "Epoch 070, Loss: 0.0207, Prediction: ello\n",
            "Epoch 080, Loss: 0.0138, Prediction: ello\n",
            "Epoch 090, Loss: 0.0101, Prediction: ello\n",
            "Epoch 100, Loss: 0.0080, Prediction: ello\n",
            "\n",
            "✅ Training Complete!\n"
          ]
        }
      ],
      "source": [
        "# ✅ LSTM Character Predictor in Google Colab\n",
        "\n",
        "# Step 1: Imports and Device Setup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Step 2: Sample Sequence and Preprocessing\n",
        "sequence = \"hello\"\n",
        "chars = list(set(sequence))  # Unique characters\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
        "\n",
        "input_seq = [char_to_idx[ch] for ch in sequence[:-1]]  # 'h', 'e', 'l', 'l'\n",
        "target_seq = [char_to_idx[ch] for ch in sequence[1:]]  # 'e', 'l', 'l', 'o'\n",
        "\n",
        "# One-hot encoding input\n",
        "input_tensor = torch.eye(len(chars))[input_seq].unsqueeze(1).to(device)  # Shape: (seq_len, batch, input_size)\n",
        "target_tensor = torch.tensor(target_seq).to(device)\n",
        "\n",
        "# Step 3: Define the LSTM Model\n",
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CharLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, (hidden, cell) = self.lstm(x)\n",
        "        out = self.fc(out.view(-1, out.shape[2]))  # Flatten and pass through FC\n",
        "        return out\n",
        "\n",
        "# Step 4: Initialize and Train the Model\n",
        "input_size = len(chars)\n",
        "hidden_size = 16\n",
        "output_size = len(chars)\n",
        "num_epochs = 100\n",
        "\n",
        "model = CharLSTM(input_size, hidden_size, output_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "print(\"\\nTraining...\\n\")\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_tensor)\n",
        "    loss = criterion(output, target_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        pred = output.argmax(dim=1)\n",
        "        pred_str = ''.join([idx_to_char[i.item()] for i in pred])\n",
        "        print(f\"Epoch {epoch+1:03}, Loss: {loss.item():.4f}, Prediction: {pred_str}\")\n",
        "\n",
        "print(\"\\n✅ Training Complete!\")\n"
      ]
    }
  ]
}