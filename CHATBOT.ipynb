{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8tfmDDM8oar8EIF3Skl89",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abishekraja018/SDC-GENAI/blob/main/CHATBOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch transformers langchain --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load the pre-trained model and tokenizer locally\n",
        "model_name = \"EleutherAI/gpt-neo-125M\"  # You can change this to any other model you have access to\n",
        "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set up device for running the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to generate chatbot response\n",
        "def chatbot_response(input_text):\n",
        "    # Encode input text and generate a response\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(inputs, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode and return the response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Interactive chatbot loop\n",
        "print(\"Chatbot: Hi! How can I help you today? (Type 'exit' to quit)\")\n",
        "\n",
        "while True:\n",
        "    # User input\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Exit condition\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Generate response\n",
        "    response = chatbot_response(user_input)\n",
        "    print(f\"Chatbot: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEPoz6NReN5F",
        "outputId": "74dd4a83-c883-4e1a-9839-b102a1129304"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m601.8/664.8 MB\u001b[0m \u001b[31m122.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
            "    unknown package:\n",
            "        Expected sha256 165764f44ef8c61fcdfdfdbe769d687e06374059fbb388b6c89ecb0e28793a6f\n",
            "             Got        27e70efeadbf2ce41c7e1413f7a4e06b8660d2fb08cd4524b4d730ee3e5508b6\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0mChatbot: Hi! How can I help you today? (Type 'exit' to quit)\n",
            "You: HOW ARE YOU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: HOW ARE YOU GONNA BE IN THE GAME?\n",
            "\n",
            "The game is a game of chance. It is the game that you play in the first place. You play the same game over and over. The game has a lot of rules.\n",
            "You play a certain number of times. If you have a chance to win, you win. But if you don’t, it‘s a different game. So, what are you doing? What are the rules? How do\n",
            "You: TODAY IS WHAT?\n",
            "Chatbot: TODAY IS WHAT?\n",
            "\n",
            "I’m not sure I‘m going to be able to answer this question, but I think it“s a good question.\n",
            "If you”re going out and looking for a new job, you can‚t go out there and look for new jobs. You�„re not going into a job search.‖\n",
            "You›re looking to find a position that you want to work for. If you\n",
            "You: EXIT\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}